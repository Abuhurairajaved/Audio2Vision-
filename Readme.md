# ğŸµ Audio2Vision

**Audio2Vision** is a multimodal AI project that takes an **audio input**, converts it into **text**, and then generates a **corresponding image** using deep learning models. The project leverages **Whisper** for speech-to-text transcription and **Stable Diffusion** for text-to-image generation.

---

## ğŸš€ Features
- ğŸ¤ **Audio to Text**: Converts audio input into text using **Whisper**.
- ğŸ–¼ **Text to Image**: Generates images from transcribed text using **Stable Diffusion**.
- ğŸ” **Self-Supervised Learning**: Fine-tuned to improve **audio-to-image** matching.
- ğŸ“Š **Dataset Handling**: Supports the **VGGSound dataset** for multimodal training.
- ğŸ— **Modular Codebase**: Clean, reusable, and well-structured for **deployment**.

---

## ğŸ›  Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/Abuhurairajaved/Audio2Vision-
cd Audio2Vision-
```

### 2ï¸âƒ£ Install Dependencies
Make sure you have Python **3.8+** and install the required packages:
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Download Dataset
Download **VGGSound** videos and extract audio:
```bash
python download_videos.py  # Downloads videos
python extract_audio.py     # Extracts audio from videos
```

### 4ï¸âƒ£ Preprocess Data
Prepare the dataset for training:
```bash
python preprocess.py
```

### 5ï¸âƒ£ Train the Model
Fine-tune the model on your dataset:
```bash
python train.py
```

### 6ï¸âƒ£ Generate Images
Test the model by generating images from new audio inputs:
```bash
python generate.py --input_audio "path/to/audio.wav"
```

---

## ğŸ“‚ Project Structure
```
Audio2Vision-
â”‚â”€â”€ dataset.py           # Loads & processes dataset
â”‚â”€â”€ extract_audio.py     # Extracts audio from videos
â”‚â”€â”€ preprocess.py        # Prepares dataset for training
â”‚â”€â”€ train.py             # Trains the AI model
â”‚â”€â”€ generate.py          # Generates images from new audio inputs
â”‚â”€â”€ README.md            # Project documentation
â”‚â”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ ...
```

---

## ğŸ–¥ Technologies Used
- **Python** ğŸ
- **Whisper** ğŸ¤ (for speech-to-text transcription)
- **Stable Diffusion** ğŸ–¼ (for text-to-image generation)
- **PyTorch** ğŸ”¥ (for deep learning training)
- **Torchaudio** ğŸµ (for audio processing)

---

## ğŸ¤ Contributors
- **[Abuhurairajaved](https://github.com/Abuhurairajaved)** (Lead Developer)

ğŸ™Œ Feel free to contribute and improve the project!

---

## ğŸ“œ License
This project is open-source and available under the **MIT License**.

---

## â­ Show Some Love!
If you found this project useful, **star** â­ the repo to support development!
